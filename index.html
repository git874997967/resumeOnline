<!DOCTYPE>
<html>

<head>
	<title>Zhenming Yang | DE SDE | zacyang0701@gmail.com</title>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="keywords" content="" />
	<meta name="description" content="" />
	<link rel="stylesheet" type="text/css" href="css/reset-fonts-grids.css" media="all" />
	<link rel="stylesheet" type="text/css" href="css/resume.css" media="all" />
	<link rel="stylesheet" type="text/css" href="css/all.min.css">
</head>

<body>
	<div id="doc2" class="yui-t7">
		<div id="inner">
			<div id="hd">
				<div class="yui-gc">
					<div class="yui-u first">
						<h1>Zhenming Yang</h1>
						<h2>Data engineer, Software Engineer</h2>
					</div>
					<div class="yui-u">
						<div class="contact-info">
							<h3><a id="pdf" href="resume.pdf">Download PDF</a></h3>
						</div>
						<!--// .contact-info -->
					</div>
					<div class="yui-u">
						<div class="contact-info">
							<a href='tel:+1-626-493-5215' one-link-mark="yes"> <i class="fas fa-phone">6264935215</i>
							</a>
						</div>
						<!--// .contact-info -->
						<div class="contact-info">
							<a href='mailto:zacyang0701@gmail.com' one-link-mark="yes"> <i class="fas fa-envelope">
									zacyang0701@gmail.com</i> </a>
						</div>
						<!--// .contact-info -->
						<div class="contact-info">
							<a href="https://www.linkedin.com/in/zac-yang/"><i class="fab fa-linkedin-in"></i></a>
						</div>
						<!--// .contact-info -->
					</div>
				</div>
				<!--// .yui-gc -->
			</div>
			<!--// hd -->
			<div id="bd">
				<div id="yui-main">
					<div class="yui-b">
						<div class="yui-gf">
							<div class="yui-u first">
								<h2>Profile</h2>
							</div>
							<div class="yui-u">
								<p class='enlarge'>
									Software Data Engineer with strong experience in Big Data solutions, SQL/NoSQL databases, and building ETL/ELT pipelines using cloud services. Proficient in AWS cloud technologies, dbt for analytics engineering, Docker for containerization, and Apache Airflow for workflow orchestration. Skilled in Python, Java, SQL, and PowerShell, with a solid foundation in Computer Science concepts and software engineering best practices. Experienced in requirement gathering and SDLC, with a focus on scalable, efficient data solutions.
								</p>
								</br>
								<p class="enlarge">
									As a Green Card holder. I do not need any sponsorship in the future.
								</p>
							</div>
						</div>
						<!-- // .yui-gf -->
						<div class="yui-gf">
							<div class="yui-u first">
								<h2>Skills</h2>
							</div>
							<div class="yui-u">
								<div class="talent_2">
									<h2>Data Engineering</h2>
									<p> Proven ability to
										use Cloud data platforms and different languages.
										Proficient in SQL and ETL process. Great experience with data modeling, large
										scale of OLAP
										nmanagement, and operations. Good at creating varied ad-hoc visuals to meet
										stakeholders' requirements. Insights the value of data.</p>
								</div>
								<div class="talent_2">
									<h2>Software Engineering</h2>
									<p>Solid understanding of fundamental Computer Science concepts.</p>
								</div>
							</div>
						</div>
						<!--// .yui-gf -->
						<div class="yui-gf">
							<div class="yui-u first">
								<h2>Technical Forte</h2>
							</div>
							<div class="yui-u">
								<ul class="talent_3">
									<li>On-prem/Cloud DB</li>
									<li>AWS/Azure</li>
									<li class="last">PySpark/Snowflake/Kafka</li>
								</ul>
								<ul class="talent_3">
									<li>ETL/ELT/DataLake/DeltaLake</li>
									<li>PySpark/DBT/Docker/Airflow</li>
									<li class="last">Powershell/R</li>
								</ul>
								<ul class="talent_3">
									<li>Python/SQL/GraphQL</li>
									<li>Data Visualizations</li>
									<li class="last">DevOps/GIT</li>

								</ul>
							</div>
						</div>
						<!--// .yui-gf-->
						<div class="yui-gf">
							<div class="yui-u first">
								<h2>Work Experience</h2>
							</div>
							<!--// .yui-u -->
							<div class="yui-u">
								<div class="job">
									<h2>Capital Group <small>Investment Group</small></h2>
									<h3>Data Engineer</h3>
									<h4>2021 Nov - 2024 Oct</h4>
									<ul>Generated Glue jobs by analyzing data from different sources. Such as files in S3, CloudWatch/CloudTrail logs, and other third-party APIs.</ul>
									<ul>Utilized Glue jobs and Lambda functions to handle data processing logics with different kinds of triggers such as SQS and Glue catalog events.</ul>
									<ul>Automated ETL process with Glue jobs by using AWS CDK which extracts CloudTrail logs into parquet files and dumps them into Athena DB.</ul>
									<ul>Initiated, Developed, and managed an ETL pipeline. Converted IRR, MoM, FundReturnRatio, and other Excel functions in Pyspark. More than 20 Lambda / Glue jobs were included for data staging, logic processing, and datasets validation. All permissions and resource access are defined in AWS CDK.</ul>
									<ul>Persistent the ETL results into Postgre DB via AWS Glue jobs. Partitioned and indexed monthly coming datasets with pre-defined store procedures to improve performance.</ul>
									<ul>Managed and automated the Glue jobs in DBT. Including the data validations, SCD checks, and documentation generation. Modularized and materialized the middle steps into tables. Other features such as seeds for ad-hoc analysis. Macro for user-defined functions.</ul>
									<ul>Rendered Postgre datasets into Tableau visuals and published them into different workspaces. Implemented Role-Level-Security to limit different data access requests.</ul>
									<ul>Read and backfill data from the Dremio data source in the AWS Glue job with rotated PAT(private access token) enabled. With the optimized indexes, the API provides the best performance when compared with APIs from by other teams.</ul>
									<ul>Modified the Sproc and tuned the data archive Sproc by modifying indexes and job schedules. Made the front-end query returned in milliseconds rather than mins than before in Postgres DB.</ul>
								</div>
								<div class="job">
									<h2>Microsoft <small>Office IP AntiSpam</small></h2>
									<h3>Software Developer</h3>
									<h4>2019 May - 2021 May</h4>
									<ul>Migrated Cosmos uploader/downloader with ScopeSDK, T-SQL, and PowerShell from old JScript logic. Equipped with alert and pipeline monitor to enhance durability. </ul>
									<ul>Troubleshoot issues, and errors in ETL services. Generated probes, monitors, and alerts for different components and services with C#, Scope language, and PowerShell. </ul>
									<ul>Built and maintained a big data platform (ADF/ADLS) in Cosmos Scope script as per industry standards and best practices.</ul>
									<ul>Performed DB admin activities on multiple DB Servers. Optimized data pipeline by rewriting new logic and SQL schema, gaining both performance and service durability. Reduced up to 20% storage cost with archiving and re-indexing stale data as well as increased the query performance.</ul>
									<ul>Optimized slow-running scope queries by using scope hints. Generate TB-level data daily basis.Implemented Ad-hoc data status monitors and dashboards with PowerBI and Lens platform. Deliver reports to end users weekly and monthly.</ul>

								</div>
								<div class="job">
									<h2>Conagra Brands Inc. <small>Cost to Serve</small> </h2>
									<h3>Data Engineer</h3>
									<h4>2018 Nov - 2019 Mar</h4>
									<ul>Designed and implemented the whole ETL (Extract, Transform, Load) data process with various transactions within SSIS packages to implement business rules and logic.</ul>
									<ul>Generated PowerBI reports, and dashboards with Star schema. Implemented complex requirements in PowerBI by using DAX and M language.</ul>
									<ul>Reduced refresh waiting time by using PowerBI API in PowerShell scripts, deployed and automated the scripts on CtrlM Servers.</ul>
									<ul>Created customized visuals with R libraries. Embedded the PowerBI visuals within the Sales-force homepage with PowerBI-JavaScript libraries.</ul>
									<ul>Accumulated agile Product Management experience - a full gamut of creating stories, generating PowerBI reports and dashboards, and working through user acceptance testing (UAT).</ul>
									<ul>Hold scrum meetings as a scrum master. Wrote various documents such as data mapping documents, work detail descriptions for KT sessions, and future development.</ul>
								</div>
								<div class="job last">
									<h2>KHDHC Inc.</h2>
									<h3>SQL ETL Developer</h3>
									<h4>2013 Sep - 2015 Mar</h4>
									<ul>Created logical and physical data models based on the requirements utilizing Erwin and NaviCat.</ul>
									<ul>Improved the performance of the official website by optimizing slowly running queries, and utilized indexes, partitions, and deadlock monitor via SQL Profiler and DTA.</ul>
									<ul>Normalized database tables to avoid redundancy and DML anomalies.</ul>
									<ul>Developed complex SQL scripts and procedures for data profiling and auditing purposes. Combined C# logic in SSIS packages.</ul>
									<ul>Utilized Microsoft SSIS/SSAS/SSRS to handle ETL logic, and create ad-hoc reports with both tabular model and cube model.</ul>
									<ul>Developed various Dashboards and Stories using advanced Tableau features including calculated fields, parameters, table calculations, row-level security, R integration, and dashboard actions while dealing with Cloud data in SSRS.</ul>
								</div>
							</div>
							<!--// .yui-u -->
						</div>
						<!--// .yui-gf -->
						<div class="yui-gf">
							<div class="yui-u first">
								<h2>Other Projects</h2>
							</div>
							<div class="yui-u">
								<div class="job">
									<h2>Kaggle Data Science projects</h2>
									<h4>2017-2018</h4>
									<ul>Performed data preprocessing and feature engineering, including correlation
										analysis, Box-Cox transformation, encoding, etc.</ul>
									<ul>Built and hyper-tuned several lasso regression models and Xgboost models, with
										cross-validation.</ul>
									<ul>Built an average model of all model predictions.</ul>

								</div>
								<div class="job last">
									<h2>Graduation Project: Diamond price prediction.</h2>
									<h4>2017-2018</h4>
									<ul>Collected diamond data (570K+ records) with JS crawler PhantomJS from BlueNiles.
										Followed with Data Mining steps(data label, data cleansing, One-Hot Encoder,and
										PCA, etc).Created predictive analysis model that predicts with up to 93%
										accuracy the likelihood of correction of predicting price with 10-fold
										cross-validation.</ul>
									<ul> Implemented multiple ML models (linear regression, decision tree, and
										random forest) in OpenR and Intel MKL library.</ul>
									<ul>Developed an Interactive GUI platform(mobile friendly) for presenting ML models
										with Bootstrap framework and
										Rshiny server.</ul>
								</div>
							</div>
						</div>
						<!--// .yui-gf -->

						<div class="yui-gf">
							<div class="yui-u first">
								<h2>Education</h2>
							</div>
							<div class="yui-u">
								<h2>Oregon State University - Corvallis, Oregon</h2>
								<h3>Master in Computer Science </h3>
							</div>
						</div>
						<!--// .yui-gf -->
						<div class="yui-gf last">
							<div class="yui-u first">
								<h2>Certificates</h2>
							</div>
							<div class="yui-u">
								<h3>Microsoft Certified:Azure Database Administrator Associate</h3>
								<h3>Microsoft Certified:Data Analyst Associate</h3>
							</div>
						</div>
						<!--// .yui-gf -->


					</div>
					<!--// .yui-b -->
				</div>
				<!--// yui-main -->
			</div>
			<!--// bd -->

			<div id="ft">
				<h3>Zac Yang &nbsp;<a href='tel:+1-626-493-5215' one-link-mark="yes"> <i
							class="fas fa-phone">6264935215</i> </a>
					<a href='mailto:zacyang0701@gmail.com' one-link-mark="yes"> <i class="fas fa-envelope">
							zacyang0701@gmail.com</i> </a>
					<a href="https://www.linkedin.com/in/zac-yang/"><i class="fab fa-linkedin-in"></i></a>
			</div>
			<!--// footer -->

		</div><!-- // inner -->


	</div>
	<!--// doc -->


</body>

</html>